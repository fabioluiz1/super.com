# FastAPI Async vs Sync Frameworks (Flask, Django)

## Why async matters for DB-bound APIs

In a sync framework like Flask or Django, a database query that takes 50ms blocks the entire thread. If you have 4 worker threads and 5 concurrent requests, the 5th request waits — even though 4 threads are just sitting idle waiting for Postgres to respond. Scaling means spawning more threads or processes (Gunicorn workers), each consuming ~30MB of RAM.

With async, the `await db.execute()` call yields control back to the event loop while waiting for Postgres. That same single process handles all 5 requests concurrently — during the 50ms one request waits for the DB, the event loop serves others. You scale with a single process and a connection pool, not by multiplying OS processes.

In practice: a sync Flask app needs 16+ Gunicorn workers to handle 100 concurrent DB-bound requests. An async FastAPI app handles the same load with 1 process and a `pool_size=15` connection pool.

## Visual comparison

```
SYNC (Flask + Gunicorn) — 1 process per worker, 1 thread per request
=====================================================================

  Process 1 (Worker)     Process 2 (Worker)     Process 3 (Worker)     Process 4 (Worker)
  ┌────────────────┐     ┌────────────────┐     ┌────────────────┐     ┌────────────────┐
  │ Thread 1       │     │ Thread 1       │     │ Thread 1       │     │ Thread 1       │
  │ Request 1      │     │ Request 2      │     │ Request 3      │     │ Request 4      │
  │ █░░░░░░░░░░█   │     │ █░░░░░░░░░░█   │     │ █░░░░░░░░░░█   │     │ █░░░░░░░░░░█   │
  └────────────────┘     └────────────────┘     └────────────────┘     └────────────────┘
        │                      │                      │                      │
        ▼                      ▼                      ▼                      ▼
     waiting for DB         waiting for DB         waiting for DB         waiting for DB
     (thread blocked,       (thread blocked,       (thread blocked,       (thread blocked,
      RAM held ~30 MB)       RAM held ~30 MB)       RAM held ~30 MB)       RAM held ~30 MB)

  Request 5 ──▶ ⏳ QUEUED — no free worker process

  Total: 4 processes × ~30 MB = 120 MB to handle 4 concurrent requests


ASYNC (FastAPI + uvicorn) — 1 process, 1 thread, 1 event loop
===============================================================

  Process 1
  ┌──────────────────────────────────────────────────────────┐
  │ Event Loop (single thread)                               │
  │                                                          │
  │  time ──▶  t0    t1    t2    t3    t4    t5    t6        │
  │                                                          │
  │  Req 1:    █░░░░░░░░░░█                                  │
  │  Req 2:     █░░░░░░░░░░█                                 │
  │  Req 3:      █░░░░░░░░░░█                                │
  │  Req 4:       █░░░░░░░░░░█                               │
  │  Req 5:        █░░░░░░░░░░█                              │
  │                                                          │
  │  █ = CPU work (parse request, build response)            │
  │  ░ = yielded to event loop (await db.execute)            │
  │      → loop serves other requests during this time       │
  └──────────────────────────────────────────────────────────┘

  Total: 1 process × ~50 MB = 50 MB to handle 100s of concurrent requests
```

Each sync worker is a separate OS process with its own memory. While a thread waits for Postgres (the `░` segments), it does nothing — it just holds RAM. Scaling means spawning more processes.

The async event loop is a single thread in a single process. When a request hits `await db.execute()`, it yields control — the loop immediately picks up the next request. No extra processes, no extra threads, no wasted memory.
